{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Classification with the GTZAN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import imageio.v3\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pop', 'metal', 'disco', 'blues', 'reggae', 'classical', 'rock', 'hiphop', 'country', 'jazz']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pop': 0,\n",
       " 'metal': 1,\n",
       " 'disco': 2,\n",
       " 'blues': 3,\n",
       " 'reggae': 4,\n",
       " 'classical': 5,\n",
       " 'rock': 6,\n",
       " 'hiphop': 7,\n",
       " 'country': 8,\n",
       " 'jazz': 9}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = os.listdir('Data/genres_original/')\n",
    "print(genres)\n",
    "genre_dict = {genres[i]: i for i in range(len(genres))}\n",
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues_00000_0.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues_00000_1.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues_00000_2.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues_00000_3.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues_00000_4.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>rock_00099_5.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.349126</td>\n",
       "      <td>0.080515</td>\n",
       "      <td>0.050019</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1499.083005</td>\n",
       "      <td>164266.886443</td>\n",
       "      <td>1718.707215</td>\n",
       "      <td>85931.574523</td>\n",
       "      <td>...</td>\n",
       "      <td>42.485981</td>\n",
       "      <td>-9.094270</td>\n",
       "      <td>38.326839</td>\n",
       "      <td>-4.246976</td>\n",
       "      <td>31.049839</td>\n",
       "      <td>-5.625813</td>\n",
       "      <td>48.804092</td>\n",
       "      <td>1.818823</td>\n",
       "      <td>38.966969</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>rock_00099_6.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.372564</td>\n",
       "      <td>0.082626</td>\n",
       "      <td>0.057897</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1847.965128</td>\n",
       "      <td>281054.935973</td>\n",
       "      <td>1906.468492</td>\n",
       "      <td>99727.037054</td>\n",
       "      <td>...</td>\n",
       "      <td>32.415203</td>\n",
       "      <td>-12.375726</td>\n",
       "      <td>66.418587</td>\n",
       "      <td>-3.081278</td>\n",
       "      <td>54.414265</td>\n",
       "      <td>-11.960546</td>\n",
       "      <td>63.452255</td>\n",
       "      <td>0.428857</td>\n",
       "      <td>18.697033</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>rock_00099_7.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.347481</td>\n",
       "      <td>0.089019</td>\n",
       "      <td>0.052403</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>1346.157659</td>\n",
       "      <td>662956.246325</td>\n",
       "      <td>1561.859087</td>\n",
       "      <td>138762.841945</td>\n",
       "      <td>...</td>\n",
       "      <td>78.228149</td>\n",
       "      <td>-2.524483</td>\n",
       "      <td>21.778994</td>\n",
       "      <td>4.809936</td>\n",
       "      <td>25.980829</td>\n",
       "      <td>1.775686</td>\n",
       "      <td>48.582378</td>\n",
       "      <td>-0.299545</td>\n",
       "      <td>41.586990</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>rock_00099_8.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.387527</td>\n",
       "      <td>0.084815</td>\n",
       "      <td>0.066430</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>2084.515327</td>\n",
       "      <td>203891.039161</td>\n",
       "      <td>2018.366254</td>\n",
       "      <td>22860.992562</td>\n",
       "      <td>...</td>\n",
       "      <td>28.323744</td>\n",
       "      <td>-5.363541</td>\n",
       "      <td>17.209942</td>\n",
       "      <td>6.462601</td>\n",
       "      <td>21.442928</td>\n",
       "      <td>2.354765</td>\n",
       "      <td>24.843613</td>\n",
       "      <td>0.675824</td>\n",
       "      <td>12.787750</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>rock_00099_9.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.369293</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>0.050524</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1634.330126</td>\n",
       "      <td>411429.169769</td>\n",
       "      <td>1867.422378</td>\n",
       "      <td>119722.211518</td>\n",
       "      <td>...</td>\n",
       "      <td>38.801735</td>\n",
       "      <td>-11.598399</td>\n",
       "      <td>58.983097</td>\n",
       "      <td>-0.178517</td>\n",
       "      <td>55.761299</td>\n",
       "      <td>-6.903252</td>\n",
       "      <td>39.485901</td>\n",
       "      <td>-3.412534</td>\n",
       "      <td>31.727489</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9990 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0     blues_00000_0.wav   66149          0.335406         0.091048  0.130405   \n",
       "1     blues_00000_1.wav   66149          0.343065         0.086147  0.112699   \n",
       "2     blues_00000_2.wav   66149          0.346815         0.092243  0.132003   \n",
       "3     blues_00000_3.wav   66149          0.363639         0.086856  0.132565   \n",
       "4     blues_00000_4.wav   66149          0.335579         0.088129  0.143289   \n",
       "...                 ...     ...               ...              ...       ...   \n",
       "9985   rock_00099_5.wav   66149          0.349126         0.080515  0.050019   \n",
       "9986   rock_00099_6.wav   66149          0.372564         0.082626  0.057897   \n",
       "9987   rock_00099_7.wav   66149          0.347481         0.089019  0.052403   \n",
       "9988   rock_00099_8.wav   66149          0.387527         0.084815  0.066430   \n",
       "9989   rock_00099_9.wav   66149          0.369293         0.086759  0.050524   \n",
       "\n",
       "       rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0     0.003521             1773.065032          167541.630869   \n",
       "1     0.001450             1816.693777           90525.690866   \n",
       "2     0.004620             1788.539719          111407.437613   \n",
       "3     0.002448             1655.289045          111952.284517   \n",
       "4     0.001701             1630.656199           79667.267654   \n",
       "...        ...                     ...                    ...   \n",
       "9985  0.000097             1499.083005          164266.886443   \n",
       "9986  0.000088             1847.965128          281054.935973   \n",
       "9987  0.000701             1346.157659          662956.246325   \n",
       "9988  0.000320             2084.515327          203891.039161   \n",
       "9989  0.000067             1634.330126          411429.169769   \n",
       "\n",
       "      spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0                 1972.744388           117335.771563  ...   39.687145   \n",
       "1                 2010.051501            65671.875673  ...   64.748276   \n",
       "2                 2084.565132            75124.921716  ...   67.336563   \n",
       "3                 1960.039988            82913.639269  ...   47.739452   \n",
       "4                 1948.503884            60204.020268  ...   30.336359   \n",
       "...                       ...                     ...  ...         ...   \n",
       "9985              1718.707215            85931.574523  ...   42.485981   \n",
       "9986              1906.468492            99727.037054  ...   32.415203   \n",
       "9987              1561.859087           138762.841945  ...   78.228149   \n",
       "9988              2018.366254            22860.992562  ...   28.323744   \n",
       "9989              1867.422378           119722.211518  ...   38.801735   \n",
       "\n",
       "      mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  \\\n",
       "0       -3.241280   36.488243     0.722209   38.099152    -5.050335   \n",
       "1       -6.055294   40.677654     0.159015   51.264091    -2.837699   \n",
       "2       -1.768610   28.348579     2.378768   45.717648    -1.938424   \n",
       "3       -3.841155   28.337118     1.218588   34.770935    -3.580352   \n",
       "4        0.664582   45.880913     1.689446   51.363583    -3.392489   \n",
       "...           ...         ...          ...         ...          ...   \n",
       "9985    -9.094270   38.326839    -4.246976   31.049839    -5.625813   \n",
       "9986   -12.375726   66.418587    -3.081278   54.414265   -11.960546   \n",
       "9987    -2.524483   21.778994     4.809936   25.980829     1.775686   \n",
       "9988    -5.363541   17.209942     6.462601   21.442928     2.354765   \n",
       "9989   -11.598399   58.983097    -0.178517   55.761299    -6.903252   \n",
       "\n",
       "      mfcc19_var  mfcc20_mean  mfcc20_var  label  \n",
       "0      33.618073    -0.243027   43.771767  blues  \n",
       "1      97.030830     5.784063   59.943081  blues  \n",
       "2      53.050835     2.517375   33.105122  blues  \n",
       "3      50.836224     3.630866   32.023678  blues  \n",
       "4      26.738789     0.536961   29.146694  blues  \n",
       "...          ...          ...         ...    ...  \n",
       "9985   48.804092     1.818823   38.966969   rock  \n",
       "9986   63.452255     0.428857   18.697033   rock  \n",
       "9987   48.582378    -0.299545   41.586990   rock  \n",
       "9988   24.843613     0.675824   12.787750   rock  \n",
       "9989   39.485901    -3.412534   31.727489   rock  \n",
       "\n",
       "[9990 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_sec_df = pd.read_csv('Data/features_3_sec.csv')\n",
    "\n",
    "# changing dots in middle of file name to _ because it makes more sense\n",
    "three_sec_df['filename'] = three_sec_df['filename'].apply(lambda x: f'{x[:-4].replace(\".\", \"_\")}.wav')\n",
    "\n",
    "three_sec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues_00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues_00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues_00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues_00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues_00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>rock_00095.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.352063</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>2008.149458</td>\n",
       "      <td>282174.689224</td>\n",
       "      <td>2106.541053</td>\n",
       "      <td>88609.749506</td>\n",
       "      <td>...</td>\n",
       "      <td>45.050526</td>\n",
       "      <td>-13.289984</td>\n",
       "      <td>41.754955</td>\n",
       "      <td>2.484145</td>\n",
       "      <td>36.778877</td>\n",
       "      <td>-6.713265</td>\n",
       "      <td>54.866825</td>\n",
       "      <td>-1.193787</td>\n",
       "      <td>49.950665</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>rock_00096.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.398687</td>\n",
       "      <td>0.075086</td>\n",
       "      <td>0.076458</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>2006.843354</td>\n",
       "      <td>182114.709510</td>\n",
       "      <td>2068.942009</td>\n",
       "      <td>82426.016726</td>\n",
       "      <td>...</td>\n",
       "      <td>33.851742</td>\n",
       "      <td>-10.848309</td>\n",
       "      <td>39.395096</td>\n",
       "      <td>1.881229</td>\n",
       "      <td>32.010040</td>\n",
       "      <td>-7.461491</td>\n",
       "      <td>39.196327</td>\n",
       "      <td>-2.795338</td>\n",
       "      <td>31.773624</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>rock_00097.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.432142</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>2077.526598</td>\n",
       "      <td>231657.968040</td>\n",
       "      <td>1927.293153</td>\n",
       "      <td>74717.124394</td>\n",
       "      <td>...</td>\n",
       "      <td>33.597008</td>\n",
       "      <td>-12.845291</td>\n",
       "      <td>36.367264</td>\n",
       "      <td>3.440978</td>\n",
       "      <td>36.001110</td>\n",
       "      <td>-12.588070</td>\n",
       "      <td>42.502201</td>\n",
       "      <td>-2.106337</td>\n",
       "      <td>29.865515</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>rock_00098.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.362485</td>\n",
       "      <td>0.091506</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>1398.699344</td>\n",
       "      <td>240318.731073</td>\n",
       "      <td>1818.450280</td>\n",
       "      <td>109090.207161</td>\n",
       "      <td>...</td>\n",
       "      <td>46.324894</td>\n",
       "      <td>-4.416050</td>\n",
       "      <td>43.583942</td>\n",
       "      <td>1.556207</td>\n",
       "      <td>34.331261</td>\n",
       "      <td>-5.041897</td>\n",
       "      <td>47.227180</td>\n",
       "      <td>-3.590644</td>\n",
       "      <td>41.299088</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>rock_00099.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.358401</td>\n",
       "      <td>0.085884</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>1609.795082</td>\n",
       "      <td>422203.216152</td>\n",
       "      <td>1797.213044</td>\n",
       "      <td>120115.632927</td>\n",
       "      <td>...</td>\n",
       "      <td>59.167755</td>\n",
       "      <td>-7.069775</td>\n",
       "      <td>73.760391</td>\n",
       "      <td>0.028346</td>\n",
       "      <td>76.504326</td>\n",
       "      <td>-2.025783</td>\n",
       "      <td>72.189316</td>\n",
       "      <td>1.155239</td>\n",
       "      <td>49.662510</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0    blues_00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1    blues_00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2    blues_00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3    blues_00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4    blues_00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "..               ...     ...               ...              ...       ...   \n",
       "995   rock_00095.wav  661794          0.352063         0.080487  0.079486   \n",
       "996   rock_00096.wav  661794          0.398687         0.075086  0.076458   \n",
       "997   rock_00097.wav  661794          0.432142         0.075268  0.081651   \n",
       "998   rock_00098.wav  661794          0.362485         0.091506  0.083860   \n",
       "999   rock_00099.wav  661794          0.358401         0.085884  0.054454   \n",
       "\n",
       "      rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0    0.002827             1784.165850          129774.064525   \n",
       "1    0.002373             1530.176679          375850.073649   \n",
       "2    0.002746             1552.811865          156467.643368   \n",
       "3    0.006346             1070.106615          184355.942417   \n",
       "4    0.002303             1835.004266          343399.939274   \n",
       "..        ...                     ...                    ...   \n",
       "995  0.000345             2008.149458          282174.689224   \n",
       "996  0.000588             2006.843354          182114.709510   \n",
       "997  0.000322             2077.526598          231657.968040   \n",
       "998  0.001211             1398.699344          240318.731073   \n",
       "999  0.000336             1609.795082          422203.216152   \n",
       "\n",
       "     spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0                2002.449060            85882.761315  ...   52.420910   \n",
       "1                2039.036516           213843.755497  ...   55.356403   \n",
       "2                1747.702312            76254.192257  ...   40.598766   \n",
       "3                1596.412872           166441.494769  ...   44.427753   \n",
       "4                1748.172116            88445.209036  ...   86.099236   \n",
       "..                       ...                     ...  ...         ...   \n",
       "995              2106.541053            88609.749506  ...   45.050526   \n",
       "996              2068.942009            82426.016726  ...   33.851742   \n",
       "997              1927.293153            74717.124394  ...   33.597008   \n",
       "998              1818.450280           109090.207161  ...   46.324894   \n",
       "999              1797.213044           120115.632927  ...   59.167755   \n",
       "\n",
       "     mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  \\\n",
       "0      -1.690215   36.524071    -0.408979   41.597103    -2.303523   \n",
       "1      -0.731125   60.314529     0.295073   48.120598    -0.283518   \n",
       "2      -7.729093   47.639427    -1.816407   52.382141    -3.439720   \n",
       "3      -3.319597   50.206673     0.636965   37.319130    -0.619121   \n",
       "4      -5.454034   75.269707    -0.916874   53.613918    -4.404827   \n",
       "..           ...         ...          ...         ...          ...   \n",
       "995   -13.289984   41.754955     2.484145   36.778877    -6.713265   \n",
       "996   -10.848309   39.395096     1.881229   32.010040    -7.461491   \n",
       "997   -12.845291   36.367264     3.440978   36.001110   -12.588070   \n",
       "998    -4.416050   43.583942     1.556207   34.331261    -5.041897   \n",
       "999    -7.069775   73.760391     0.028346   76.504326    -2.025783   \n",
       "\n",
       "     mfcc19_var  mfcc20_mean  mfcc20_var  label  \n",
       "0     55.062923     1.221291   46.936035  blues  \n",
       "1     51.106190     0.531217   45.786282  blues  \n",
       "2     46.639660    -2.231258   30.573025  blues  \n",
       "3     37.259739    -3.407448   31.949339  blues  \n",
       "4     62.910812   -11.703234   55.195160  blues  \n",
       "..          ...          ...         ...    ...  \n",
       "995   54.866825    -1.193787   49.950665   rock  \n",
       "996   39.196327    -2.795338   31.773624   rock  \n",
       "997   42.502201    -2.106337   29.865515   rock  \n",
       "998   47.227180    -3.590644   41.299088   rock  \n",
       "999   72.189316     1.155239   49.662510   rock  \n",
       "\n",
       "[999 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirty_sec_df = pd.read_csv('Data/features_30_sec.csv')\n",
    "thirty_sec_df['filename'] = thirty_sec_df['filename'].apply(lambda x: f'{x[:-4].replace(\".\", \"_\")}.wav')\n",
    "thirty_sec_df = thirty_sec_df.drop([554]) # dropping entry that does not have spectrogram\n",
    "thirty_sec_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, length, chroma_stft_mean, chroma_stft_var, rms_mean, rms_var, spectral_centroid_mean, spectral_centroid_var, spectral_bandwidth_mean, spectral_bandwidth_var, rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var, harmony_mean, harmony_var, perceptr_mean, perceptr_var, tempo, mfcc1_mean, mfcc1_var, mfcc2_mean, mfcc2_var, mfcc3_mean, mfcc3_var, mfcc4_mean, mfcc4_var, mfcc5_mean, mfcc5_var, mfcc6_mean, mfcc6_var, mfcc7_mean, mfcc7_var, mfcc8_mean, mfcc8_var, mfcc9_mean, mfcc9_var, mfcc10_mean, mfcc10_var, mfcc11_mean, mfcc11_var, mfcc12_mean, mfcc12_var, mfcc13_mean, mfcc13_var, mfcc14_mean, mfcc14_var, mfcc15_mean, mfcc15_var, mfcc16_mean, mfcc16_var, mfcc17_mean, mfcc17_var, mfcc18_mean, mfcc18_var, mfcc19_mean, mfcc19_var, mfcc20_mean, mfcc20_var, label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirty_sec_df.loc[thirty_sec_df['filename'] == 'jazz_00054.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the \".\" from the middle of file names and replacing with \"_\" in audio folders to match the spectrogram files and also because it's really stupid to put a . in the middle of a filename\n",
    "# Run this only once because otherwise it won't work if you try it again, but probably won't break anything i guess\n",
    "for genre in genres:\n",
    "    for song_id in os.listdir(f'Data/genres_original/{genre}'):\n",
    "        #print(song_id[:-4].replace(\".\", \"\"))\n",
    "        os.rename(f'Data/genres_original/{genre}/{song_id}', f'Data/genres_original/{genre}/{song_id[:-4].replace(\".\", \"_\")}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        genre_number = genre_dict[self.data.iloc[idx]['label']]\n",
    "        y = [1 if i == genre_number  else 0 for i in range(len(genres))]\n",
    "        x, _ = librosa.load(f'Data/genres_original/{genres[genre_number]}/{self.data.iloc[idx][\"filename\"][:-4]}.wav')\n",
    "        #print(x.shape)\n",
    "        if x.shape[0] < 675808:\n",
    "            x = np.append(x, np.zeros(675808 - len(x)))\n",
    "            #print(type(x[0]))\n",
    "         \n",
    "        return torch.Tensor(np.array([x.astype('float32')])), torch.Tensor(np.array(y).astype('float32'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blues'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirty_sec_df.iloc[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        genre_number = genre_dict[self.data.iloc[idx]['label']]\n",
    "        #print(self.data.iloc[idx]['label'])\n",
    "        y = [1 if i == genre_number  else 0 for i in range(len(genres))]\n",
    "        #print(genre_number)\n",
    "        #print(y)\n",
    "        #print(genres[y])\n",
    "        image = imageio.v3.imread(f'Data/images_original/{genres[genre_number]}/{self.data.iloc[idx][\"filename\"][:-4].replace(\"_\", \"\")}.png')\n",
    "        x = torch.Tensor(image)\n",
    "        x = torch.reshape(x, (4, 288, 432))\n",
    "        #print(x.shape)\n",
    "       \n",
    "        #plt.imshow(x)\n",
    "        return x, torch.Tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_set, test_set = train_test_split(thirty_sec_df, test_size = 0.2)\n",
    "train_set, val_set = train_test_split(train_set, test_size = 0.2)\n",
    "\n",
    "audio_train = AudioDataset(train_set)\n",
    "audio_val = AudioDataset(val_set)\n",
    "audio_test = AudioDataset(test_set)\n",
    "\n",
    "audio_train_dl = DataLoader(audio_train, batch_size=1)\n",
    "audio_val_dl = DataLoader(audio_val, batch_size=1)\n",
    "audio_test_dl = DataLoader(audio_test, batch_size=1)\n",
    "\n",
    "spec_train = SpectrogramDataset(train_set)\n",
    "spec_val = SpectrogramDataset(val_set)\n",
    "spec_test = SpectrogramDataset(test_set)\n",
    "\n",
    "spec_train_dl = DataLoader(spec_train, shuffle=True, batch_size=batch_size)\n",
    "spec_val_dl = DataLoader(spec_val, shuffle=True, batch_size=batch_size)\n",
    "spec_test_dl = DataLoader(spec_test, shuffle=True, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0422, -0.1986, -0.2465,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([ 0.0286,  0.0132, -0.0219,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.1663, 0.1911, 0.1969,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.0563, 0.0918, 0.1017,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.0624, 0.0481, 0.0356,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.0177,  0.0165,  0.0522,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([ 0.0032, -0.0070, -0.0274,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0294, -0.0371, -0.0275,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0208, 0.0875, 0.0679,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.0401, 0.0560, 0.0395,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([ 0.0050, -0.0015, -0.0091,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0373,  0.0169,  0.0081,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0721, -0.0685, -0.0671,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0304, -0.0220, -0.0236,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0648, -0.1072, -0.1094,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0614, -0.0942, -0.0792,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0514, 0.0710, 0.0240,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.7692, 0.2246, 0.6904,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.1311, -0.1124, -0.0232,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0105, 0.0132, 0.0143,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.0649, 0.0566, 0.0802,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.0858, -0.1429, -0.1270,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.3999, 0.5677, 0.3338,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.2492, -0.3290, -0.1552,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0803, -0.0750, -0.0654,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0066, -0.0092, -0.0061,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0191,  0.0111, -0.0046,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0096,  0.0019,  0.2128,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0230, -0.0298, -0.0196,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.1464, -0.2249, -0.2112,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([ 0.0113,  0.0052, -0.0008,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.2848, 0.2408, 0.3191,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.0028, -0.0126, -0.0124,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.1024, -0.0616, -0.1199,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([-0.0620, -0.0648,  0.0127,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0617, 0.0610, 0.0601,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([ 0.0257, -0.0327, -0.0194,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0512, 0.0467, 0.1004,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.0235, -0.0336, -0.0353,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.1541, 0.1752, 0.0731,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.0103,  0.0995,  0.2611,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.2289, 0.2520, 0.0956,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.1456, 0.0917, 0.0355,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.0497, -0.0860, -0.0862,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0649, 0.0627, 0.0592,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.0358, -0.0669, -0.0302,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0008, 0.0017, 0.0018,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.1152, 0.0667, 0.0091,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([-0.1373, -0.1457, -0.0453,  ...,  0.0000,  0.0000,  0.0000])\n",
      "tensor([0.0195, 0.0746, 0.1139,  ..., 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(audio_train[i][0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_98697/4291303028.py:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525473998/work/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "  x = torch.Tensor(image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n",
      "torch.Size([4, 288, 432])\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(spec_train[i][0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that spectrogram looks awful but that's just some torch tensor garbage, the actual spectrograms are still good\n",
    "matplotlib just doesn't like torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardSpectrogramModel(\n",
      "  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (norm5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (relu3): ReLU()\n",
      "  (dropout4): Dropout(p=0.5, inplace=False)\n",
      "  (norm6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "  (relu4): ReLU()\n",
      "  (dropout5): Dropout(p=0.5, inplace=False)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout6): Dropout(p=0.5, inplace=False)\n",
      "  (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (relu5): ReLU()\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "  (relu6): ReLU()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (softmax): LogSoftmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "input_shape = (batch_size, 4, 288, 432)\n",
    "\n",
    "class FeedforwardSpectrogramModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 32, 3, stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout()\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.norm4 = nn.BatchNorm2d(64)\n",
    "        self.dropout3 = nn.Dropout()\n",
    "        \n",
    "        self.norm5 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, stride=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout()\n",
    "        self.norm6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.norm7 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 1, stride=2)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout5 = nn.Dropout()\n",
    "        self.norm8 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.norm9 = nn.BatchNorm2d(256)\n",
    "        self.dropout6 = nn.Dropout()\n",
    "        \n",
    "        \n",
    "        self.conv5 = nn.Conv2d(32, 64, 3, stride=2)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(2, 2)\n",
    "        self.conv6 = nn.Conv2d(64, 64, 1, stride=2)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.dense = nn.Linear(256, 10)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print('before first conv block')\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.norm4(x)\n",
    "        x = self.dropout6(x)\n",
    "\n",
    "        #print('before second conv block')\n",
    "        x = self.norm5(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.norm6(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.norm7(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.norm8(x)\n",
    "        x = self.dropout6(x)\n",
    "     \n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        #print('before third conv block')\n",
    "        x = self.conv5(x)\n",
    "        x = self.pool5(x)\n",
    "        print('before conv6')\n",
    "        x = self.conv6(x)\n",
    "        x = self.pol(6)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.relu3(x)\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        out = self.softmax(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = FeedforwardSpectrogramModel().to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, device, optimizer, log_interval, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    counter = []\n",
    "\n",
    "    for i, (img, label) in enumerate(train_loader):\n",
    "        #print(img)\n",
    "        #print(img.shape)\n",
    "        #print(label)\n",
    "\n",
    "        #print(label.shape)\n",
    "        #print(img.shape)\n",
    "\n",
    "        #print(img)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        # img = torch.flatten(img)\n",
    "        #print((img.dtype))\n",
    "        #print(img.shape)\n",
    "        #print(img)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        output = model(img)\n",
    "\n",
    "        #print(output.shape)\n",
    "        output = torch.reshape(output, (1, 10))\n",
    "\n",
    "        #print(output.shape)\n",
    "        #print(label.shape)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        #print(type(output.data.dtype))\n",
    "        #print(type(label.data.dtype))\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        pred = torch.Tensor([output.data.max().item()]).type(torch.LongTensor)\n",
    "        label_idx = torch.Tensor([label.data.max().item()]).type(torch.LongTensor)\n",
    "        #print(output)\n",
    "        #print(label)\n",
    "        #print(pred)\n",
    "        #print(label_idx)\n",
    "        #print(pred.shape)\n",
    "        #print(label_idx.shape)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % log_interval == 0:\n",
    "            losses.append(loss.item())\n",
    "            counter.append(\n",
    "                (i * batch_size) + img.size(0) + epoch * len(train_loader.dataset))\n",
    "    \n",
    "    return losses, counter\n",
    "\n",
    "def test_one_epoch(test_loader, model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(test_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            # ------------------\n",
    "            # Write your implementation here.\n",
    "            \n",
    "            output = model(img)\n",
    "            output = torch.reshape(output, (1, 10))\n",
    "            pred = output.data.max(1, keepdim=True)[1] # Get index of largest log-probability and use that as prediction\n",
    "            \n",
    "            #print(pred)\n",
    "            \n",
    "            label_idx = label.data.max(1, keepdim=True)[1]\n",
    "            #print(pred.shape)\n",
    "            #print(label_idx.shape)\n",
    "\n",
    "            #print(label)\n",
    "            num_correct += output.eq(label.data.view_as(output)).sum()\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            #print(output)\n",
    "            #print(label)\n",
    "            #print(output.shape)\n",
    "            #print(label.shape)\n",
    "            test_loss += criterion(output, label)\n",
    "\n",
    "            # ------------------\n",
    "            \n",
    "    #test_loss /= len(test_loader.dataset)\n",
    "    return test_loss / (len(test_loader.dataset) / batch_size), num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_98697/2132776828.py:96: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [01:17<05:09, 77.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:02<08:11, 122.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_98697/3514535033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlr_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wavenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_val_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_val_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_98697/3514535033.py\u001b[0m in \u001b[0;36mtune_model\u001b[0;34m(lrs, n_epochs, train_loader, val_loader, gamma, type, num_channels, dilation_depth, num_repeat)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mval_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_98697/254682276.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_loader, model, device, optimizer, log_interval, epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             adagrad(\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36madagrad\u001b[0;34m(params, grads, state_sums, state_steps, has_sparse_grad, foreach, lr, weight_decay, lr_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adagrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36m_single_tensor_adagrad\u001b[0;34m(params, grads, state_sums, state_steps, lr, weight_decay, lr_decay, eps, has_sparse_grad, maximize)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mstate_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_complex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader = spec_val_dl\n",
    "val_loader = spec_val_dl\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "lrs = [0.0001, 0.0003, 0.0005, 0.0007, 0.001, 0.003, 0.005, 0.007, 0.085, 0.01, 0.03]\n",
    "max_epochs = 5\n",
    "gamma = 0.95\n",
    "\n",
    "# Recording data\n",
    "log_interval = len(train_loader) / batch_size\n",
    "def tune_model(lrs, n_epochs, train_loader=train_loader, val_loader=val_loader, gamma=gamma, type='spectrogram', num_channels=1, dilation_depth=2, num_repeat=1):\n",
    "    if type == 'wavenet':\n",
    "        model = WaveNet(num_channels, dilation_depth, num_repeat).to(DEVICE)\n",
    "    else:\n",
    "        model = FeedforwardSpectrogramModel().to(DEVICE)\n",
    "\n",
    "        model = model.float()\n",
    "        \n",
    "    lr_dict = {}\n",
    "    for lr in lrs:\n",
    "        # Instantiate optimizer (model was created in previous cell)\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "        val_losses = []\n",
    "        val_correct = []\n",
    "        for epoch in trange(n_epochs, leave=True, desc='Epochs'):\n",
    "            train_loss, counter = train_one_epoch(train_loader, model, DEVICE, optimizer, log_interval, epoch)\n",
    "            val_loss, num_correct = test_one_epoch(val_loader, model, DEVICE)\n",
    "\n",
    "            # Record results\n",
    "            train_losses.extend(train_loss)\n",
    "            train_counter.extend(counter)\n",
    "            val_losses.append(val_loss)\n",
    "            val_correct.append(num_correct)\n",
    "\n",
    "        print(f\"Val accuracy: {val_correct[-1]/len(val_loader.dataset)}\")\n",
    "        lr_dict[lr] = train_losses, train_counter, val_losses, val_correct\n",
    "\n",
    "results = tune_model(lrs, max_epochs, type='wavenet', train_loader=audio_val_dl, val_loader=audio_val_dl, num_channels=1, num_repeat=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_62309/1844547811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_losses' is not defined"
     ]
    }
   ],
   "source": [
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_62309/4138761962.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5k/k9z7r_vs0098fm1rwf519ml40000gn/T/ipykernel_62309/1012469352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m plt.plot([i * len(train_loader.dataset) for i in range(1, max_epochs + 1)], \n\u001b[1;32m      4\u001b[0m         val_losses, label='Test loss', marker='o')\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_counter' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(train_counter, train_losses, label='Train loss')\n",
    "plt.plot([i * len(train_loader.dataset) for i in range(1, max_epochs + 1)], \n",
    "        val_losses, label='Test loss', marker='o')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.title('Loss curve', fontsize=24)\n",
    "plt.xlabel('Number of training examples seen', fontsize=16)\n",
    "plt.ylabel('Cross Entropy Loss', fontsize=16)\n",
    "plt.legend(loc='upper right', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '008lr_100epochs.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the Raw Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(torch.nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        self.__padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=self.__padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        #print(input.shape)\n",
    "        #print(self.in_channels)\n",
    "        #print(self.out_channels)\n",
    "        result = super(CausalConv1d, self).forward(input)\n",
    "\n",
    "        if self.__padding != 0:\n",
    "            return result[:, :, : -self.__padding]\n",
    "        return result\n",
    "\n",
    "def _conv_stack(dilations, in_channels, out_channels, kernel_size):\n",
    "    \"\"\"\n",
    "    Create stack of dilated convolutional layers, outlined in WaveNet paper:\n",
    "    https://arxiv.org/pdf/1609.03499.pdf\n",
    "    \"\"\"\n",
    "    return nn.ModuleList(\n",
    "        [\n",
    "            CausalConv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                dilation=d,\n",
    "                kernel_size=kernel_size,\n",
    "            )\n",
    "            for i, d in enumerate(dilations)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, num_channels, dilation_depth, num_repeat, kernel_size=2):\n",
    "        super(WaveNet, self).__init__()\n",
    "        dilations = [2 ** d for d in range(dilation_depth)] * num_repeat\n",
    "        internal_channels = int(num_channels * 2)\n",
    "        self.hidden = _conv_stack(dilations, num_channels, internal_channels, kernel_size)\n",
    "        self.residuals = _conv_stack(dilations, num_channels, num_channels, 1)\n",
    "        self.input_layer = CausalConv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=num_channels,\n",
    "            kernel_size=1,\n",
    "            groups=1,\n",
    "        )\n",
    "\n",
    "        self.linear_mix = nn.Conv1d(\n",
    "            in_channels=num_channels * dilation_depth * num_repeat,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.dense = nn.Linear(675808, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        skips = []\n",
    "\n",
    "        #print(self.input_layer.__str__)\n",
    "        \n",
    "        out = self.input_layer(out)\n",
    "\n",
    "        for hidden, residual in zip(self.hidden, self.residuals):\n",
    "            x = out\n",
    "            out_hidden = hidden(x)\n",
    "\n",
    "            # gated activation\n",
    "            #   split (32,16,3) into two (16,16,3) for tanh and sigm calculations\n",
    "            out_hidden_split = torch.split(out_hidden, self.num_channels, dim=1)\n",
    "            out = torch.tanh(out_hidden_split[0]) * torch.sigmoid(out_hidden_split[1])\n",
    "\n",
    "            skips.append(out)\n",
    "\n",
    "            out = residual(out)\n",
    "            out = out + x[:, :, -out.size(2) :]\n",
    "\n",
    "        # modified \"postprocess\" step:\n",
    "        out = torch.cat([s[:, :, -out.size(2) :] for s in skips], dim=1)\n",
    "        out = self.linear_mix(out)\n",
    "\n",
    "        out = self.dense(out)\n",
    "        out = self.softmax(out) \n",
    "        \n",
    "        return out\n",
    "    \n",
    "wavenet = WaveNet(num_channels=4, dilation_depth=3, num_repeat=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
